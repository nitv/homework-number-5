---
title: "homework-number-5"
author: "Nitin Verma"
date: "November 18, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(curl)

f <- curl("https://raw.githubusercontent.com/difiore/ADA2016/master/KamilarAndCooperData.csv")
d <- read.csv(f, header=TRUE, stringsAsFactors=TRUE)
head(d)
```
##Part 1
**Using the "KamilarAndCooperData.csv" dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).**
```{r}
y <- log(d$HomeRange_km2)
x <- log(d$Body_mass_female_mean)

m <- lm(data=d, y ~ x)
summary(m)

beta0 <- m$coefficients[1]
beta1 <- m$coefficients[2]

beta0
beta1
```

## Part 2
**Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.**
```{r}
#ds <- d[, c("HomeRange_km2", "Body_mass_female_mean")]
#head(ds)
#ds <- na.omit(ds)
#head(ds)
n <- nrow(d)

beta0s <- NULL
beta1s <- NULL

for (i in 1:1000) {
  ds <- d[sample(c(1:n), n, replace=TRUE), ]
  ys <- log(ds$HomeRange_km2)
  xs <- log(ds$Body_mass_female_mean)
  ms <- lm(data=ds, ys ~ xs)
  
  beta0s[i] <- ms$coefficients[1]
  beta1s[i] <- ms$coefficients[2]
}
```

###Part 2a
**Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.**
```{r}
se.beta0s <- sd(beta0s)
se.beta1s <- sd(beta1s)
se.beta0s
se.beta1s

critval.beta0s <- qt(0.975, df= length(beta0s) - 1)
critval.beta1s <- qt(0.975, df= length(beta1s) - 1)

CI.beta0s = mean(beta0s) + c(-1, 1) * critval.beta0s * se.beta0s
CI.beta1s = mean(beta1s) + c(-1, 1) * critval.beta1s * se.beta1s

CI.beta0s
CI.beta1s
```

###Part 2b
**How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?**

The SEs we calculated for `beta0` (`r se.beta0s`) and `beta1` (`r se.beta1s`) compare very well to the figures generated by `lm()`.

###Part 2c
**How does the latter compare to the 95% CI estimated from your entire dataset?**

The CIs for the model `m` gotten via `lm()` can be calculated as follows:
```{r}
CI.lm <- confint(m, m$coefficients[1], 0.95)
CI.lm
```
And these CIs compare very well with those obtained from the respective sampling distributions in *Part 2a*

###Part 3: Extra credit
**Write a FUNCTION that takes as its arguments a dataframe, "d", a linear model, "m" (as a character string, e.g., "logHR~logBM"), a user-defined confidence interval level, "conf.level" (with default = 0.95), and a number of bootstrap replicates, "n" (with default = 1000). Your function should return a dataframe that includes: beta coefficient names; beta coefficients, standard errors, and upper and lower CI limits for the linear model based on your entire dataset; and mean beta coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.**

```{r}
betaCoeffAnalysis = function(d1, m1, conf.level = 0.95, n = 1000){
  if (nrow(d1) == 0 || is.null(m1)) {
    cat("ERROR!")
    return(-1)
  }
  #m1
  y1 <- strsplit(m1, "~")[[1]][[1]] #response variable
  x1 <- strsplit(m1, "~")[[1]][[2]] #predictor variable
  
  y <- log(d1[, c(y1)])
  x <- log(d1[, c(x1)])
  
  rdf <- data.frame(row.names = c("method", "beta", "est.value", "SE", "CI.lower", "CI.upper"))
  
  m <- lm(y ~ x)
  out <- summary(m)
  
  b0.lm <- out$coefficients[1,1]
  se.b0.lm <- out$coefficients[1,2]
  b1.lm <- out$coefficients[2,1]
  se.b1.lm <- out$coefficients[2,2]
  
  CI.lm <- confint(m, m$coefficients[1], 0.95)
  b0.lm.lwr <- CI.lm[1,1]
  b0.lm.upr <- CI.lm[1,2]
  b1.lm.lwr <- CI.lm[2,1]
  b1.lm.upr <- CI.lm[2,2]
  
  cat(b0.lm, se.b0.lm, b0.lm.lwr, b0.lm.upr, "\n")
  cat(b1.lm, se.b1.lm, b1.lm.lwr, b1.lm.upr, "\n")
  cat("\n")
  
  newrecord <- data.frame(method="lm", beta="beta0", est.value=b0.lm, SE=se.b0.lm, CI.lower=b0.lm.lwr, CI.upper=b0.lm.upr)
  rdf <- rbind(rdf, newrecord)
  
  newrecord <- data.frame(method="lm", beta="beta1", est.value=b1.lm, SE=se.b1.lm, CI.lower=b1.lm.lwr, CI.upper=b1.lm.upr)
  rdf <- rbind(rdf, newrecord)
  
  beta0s <- NULL
  beta1s <- NULL
  
  sz <- nrow(d1)
  for (i in 1:n) {
    
    ds <- d[sample(c(1:sz), sz, replace=TRUE), ]
    ys <- log(ds[, c(y1)])
    xs <- log(ds[, c(x1)])
    ms <- lm(ys ~ xs)
  
    beta0s[i] <- ms$coefficients[1]
    beta1s[i] <- ms$coefficients[2]
  }
  
  b0.bs <- mean(beta0s)
  b1.bs <- mean(beta1s)
  se.b0.bs <- sd(beta0s)
  se.b1.bs <- sd(beta1s)
  
  alpha <- conf.level + (1 - conf.level)/2
  
  critval.b0 <- qt(alpha, df= length(beta0s) - 1)
  critval.b1 <- qt(alpha, df= length(beta1s) - 1)
  
  CI.b0 = b0.bs + c(-1, 1) * critval.b0 * se.b0.bs
  CI.b1 = b1.bs + c(-1, 1) * critval.b1 * se.b1.bs
  
  b0.bs.lwr <- CI.b0[1]
  b0.bs.upr <- CI.b0[2]
  b1.bs.lwr <- CI.b1[1]
  b1.bs.upr <- CI.b1[2]
  
  
  newrecord = data.frame(method="bootstrap", beta="beta0", est.value=b0.bs, SE=se.b0.bs, CI.lower=b0.bs.lwr, CI.upper=b0.bs.upr)
  rdf <- rbind(rdf, newrecord)
  
  newrecord = data.frame(method="bootstrap", beta="beta1", est.value=b1.bs, SE=se.b1.bs, CI.lower=b1.bs.lwr, CI.upper=b1.bs.upr)
  rdf <- rbind(rdf, newrecord)
  
  rdf[, c(-1, -2)] <- round(rdf[, c(-1, -2)], 4)
  return(rdf)
}

betaCoeffAnalysis(d, "HomeRange_km2~Body_mass_female_mean")
```